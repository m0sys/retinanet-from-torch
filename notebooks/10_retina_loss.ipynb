{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting All of It Together (Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.util import find_spec\n",
    "if find_spec(\"model\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.matcher import Matcher\n",
    "from model.box_regression import Box2BoxTransform\n",
    "from model.loss import sigmoid_focal_loss, smooth_l1_loss\n",
    "from utils.box_utils import pairwise_iou, cat_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaLoss(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes=80,\n",
    "                 focal_loss_alpha=0.25, \n",
    "                 focal_loss_gamma=2.0, \n",
    "                 smooth_l1_beta=0.1,\n",
    "                 test_score_thresh=0.05,\n",
    "                 test_topk_candidates=1000,\n",
    "                 test_nms_thresh=0.5, \n",
    "                 max_detection_per_image=100\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.anchor_matcher = Matcher([0.4, 0.5], [-1, 0, 1])\n",
    "        self.box2box_transform = Box2BoxTransform([1., 1., 1., 1.])\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Loss params.\n",
    "        self.focal_loss_alpha = focal_loss_alpha\n",
    "        self.focal_loss_gamma = focal_loss_gamma\n",
    "        self.smooth_l1_beta = smooth_l1_beta\n",
    "        \n",
    "        # Inference params.\n",
    "        self.test_score_thresh = test_score_thresh\n",
    "        self.test_topk_candidates = test_topk_candidates\n",
    "        self.test_nms_thresh = test_nms_thresh\n",
    "        self.max_detection_per_image = max_detection_per_image\n",
    "        \n",
    "        \"\"\"\n",
    "        In Detectron1, loss is normalized by number of foreground samples in the batch.\n",
    "        When batch size is 1 per GPU, #foreground has a large variance and\n",
    "        using it lead to lower performance. Here we maintain an EMA of #foreground to\n",
    "        stabilize the normalizer.\n",
    "        \"\"\"\n",
    "        self.loss_normalizer = 100  # initialize with any reasonable #fg that's not too small\n",
    "        self.loss_normalizer_momentum = 0.9\n",
    "        \n",
    "    def forward(self, pred_logits, pred_anchor_deltas, anchors, boxes, labels):\n",
    "        gt_labels, gt_boxes = self.label_anchors(anchors, boxes, labels)\n",
    "        losses = self.losses(anchors, pred_logits, gt_labels, pred_anchor_deltas, gt_boxes)\n",
    "        return losses \n",
    "    \n",
    "    def label_anchors(self, anchors, boxes, labels):\n",
    "        anchors = cat_boxes(anchors)\n",
    "        gt_labels = []\n",
    "        matched_gt_boxes = []\n",
    "        bs = len(boxes)\n",
    "        \n",
    "        for i in range(bs):\n",
    "            matched_quality_matrix = pairwise_iou(boxes[i], anchors)\n",
    "            matched_idxs, anchor_labels = self.anchor_matcher(matched_quality_matrix)\n",
    "            del matched_quality_matrix\n",
    "            \n",
    "            if len(boxes[i]) > 0:\n",
    "                matched_gt_boxes_i = boxes[i][matched_idxs]\n",
    "                gt_labels_i = labels[i][matched_idxs]\n",
    "                # Label 0 means background. \n",
    "                gt_labels_i[anchor_labels == 0] = self.num_classes\n",
    "                # Label -1 means ignore.\n",
    "                gt_labels_i[anchor_labels == -1] = -1\n",
    "            \n",
    "            else:\n",
    "                matched_gt_boxes_i = torch.zeros_like(anchors)\n",
    "                gt_labels_i = torch.zeros_like(matched_idxs) + self.num_classes\n",
    "                \n",
    "            gt_labels.append(gt_labels_i)\n",
    "            matched_gt_boxes.append(matched_gt_boxes_i)\n",
    "        \n",
    "        return gt_labels, matched_gt_boxes\n",
    "    \n",
    "    def losses(self, anchors, pred_logits, gt_labels, pred_anchor_deltas, gt_boxes):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            anchors (list[Tensors]): a list of feature maps for each level.\n",
    "            gt_labels, gt_boxes: see output of :meth: `self.label_anchors`.\n",
    "                Their shapes are (N, R) and (N, R, 4), respectively, where R\n",
    "                is the total number of anchors across all feature levels.\n",
    "                i.e. sum(Hi x Wi x Ai)\n",
    "            pred_logits, pred_anchor_deltas: both are list[Tensor]. Each\n",
    "                element in the list corresponds to one level and has shape\n",
    "                (N, Hi x Wi x Ai, K or 4) - where K is the number of classes.\n",
    "            \n",
    "        Returns:\n",
    "            dict[str, Tensor]:\n",
    "                mapping from named loss to a scalar tensor storing the\n",
    "                loss for classification and bbox regression. Used during\n",
    "                training only. The dict keys are: \"loss_cls\" and \"loss_box_reg\".\n",
    "        \"\"\"\n",
    "        \n",
    "        num_images = len(gt_labels)\n",
    "        gt_labels = torch.stack(gt_labels).squeeze() # (N, R)\n",
    "        anchors = cat_boxes(anchors)\n",
    "        gt_anchor_deltas = [self.box2box_transform.get_deltas(anchors, k) for k in gt_boxes]\n",
    "        gt_anchor_deltas = torch.stack(gt_anchor_deltas) # (N, R, 4)\n",
    "        \n",
    "        valid_mask = gt_labels >= 0\n",
    "        pos_mask = (gt_labels >= 0) & (gt_labels != self.num_classes)\n",
    "        num_pos_anchors = pos_mask.sum().item()\n",
    "        self.loss_normalizer = self.loss_normalizer_momentum * self.loss_normalizer + (\n",
    "            1 - self.loss_normalizer_momentum\n",
    "        ) * max(num_pos_anchors, 1)\n",
    "        \n",
    "        # Classification and regression loss.\n",
    "        gt_labels_target = F.one_hot(gt_labels[valid_mask], num_classes=self.num_classes + 1)[\n",
    "            :, :-1\n",
    "        ]  # no loss for the last (bg) class\n",
    "        loss_cls = sigmoid_focal_loss(\n",
    "            torch.cat(pred_logits, dim=1)[valid_mask],\n",
    "            gt_labels_target.to(pred_logits[0].dtype),\n",
    "            alpha=self.focal_loss_alpha,\n",
    "            gamma=self.focal_loss_gamma,\n",
    "            reduction=\"sum\"\n",
    "        )\n",
    "        \n",
    "        loss_box_reg = smooth_l1_loss(\n",
    "            torch.cat(pred_anchor_deltas, dim=1)[pos_mask],\n",
    "            gt_anchor_deltas[pos_mask],\n",
    "            beta=self.smooth_l1_beta,\n",
    "            reduction=\"sum\",\n",
    "        )\n",
    "        return {\n",
    "            \"loss_cls\": loss_cls / self.loss_normalizer,\n",
    "            \"loss_box_reg\": loss_box_reg / self.loss_normalizer,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import RetinaNet500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RetinaNet500()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = RetinaLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn((16, 3, 512, 512))\n",
    "objs = [random.randint(1, 7) for _ in range(16)]\n",
    "labels = [torch.randint(0, 79, (num_o, 1)) for num_o in objs]\n",
    "boxes = [torch.randn((num_o, 4)) for num_o in objs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits, pred_bboxes, anchors = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = loss(pred_logits, pred_bboxes, anchors, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses['loss_cls'].item(), losses['loss_box_reg'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.loss import RetinaLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = loss(pred_logits, pred_bboxes, anchors, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses['loss_cls'].item(), losses['loss_box_reg'].item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
