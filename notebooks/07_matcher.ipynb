{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Matching Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.util import find_spec\n",
    "if find_spec(\"model\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.wrappers import nonzero_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Strategy.\n",
    "paper: [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher:\n",
    "    \"\"\"\n",
    "    This class assigns to each prediction \"element\" (e.g., a box) a\n",
    "    ground-truth element. Each predicted element with have exactly zero\n",
    "    or one matches. Each ground-truth element may be matched to zero or\n",
    "    more predicted elements.\n",
    "    \n",
    "    The match is determined by the MxN `match_quality_matrix`, that\n",
    "    characterizes how well each (ground-truth, prediction) pair match.\n",
    "    \n",
    "    i.e. In the case of boxes we can use the IOU between pairs. \n",
    "    \n",
    "    The matcher returns:\n",
    "        1. A vector of length N containing the index of the ground-truth\n",
    "           element m in [0, M) that matches to prediction n in [0, N).\n",
    "           \n",
    "        2. A vector of length N containing the labels for each prediction. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, thresholds: List[float], labels: List[int], allow_low_quality_matches: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            thresholds: a list of thresholds used to stratify predictions\n",
    "                into levels.\n",
    "            labels: a list of values to lable predictions belonging at each level.\n",
    "                A label can be one of {-1, 0, 1} signifying {ignore, negative class, positive class},\n",
    "                respectively.\n",
    "            allow_low_quality_matches: if True, produce additional matches for predictions\n",
    "                with maximum match quality lower than high_threshold.\n",
    "                See set_low_quality_matches_ for more details.\n",
    "        \"\"\"\n",
    "        thresholds = thresholds[:]\n",
    "        assert thresholds[0] > 0\n",
    "        thresholds.insert(0, -float(\"inf\"))\n",
    "        thresholds.append(float(\"inf\"))\n",
    "        \n",
    "        # Currently torchscript does not support all pos generator.\n",
    "        assert all([low <= high] for (low, high) in zip(thresholds[:-1], thresholds[1:]))\n",
    "        assert all([l in [-1, 0, 1] for l in labels])\n",
    "        assert len(labels) == len(thresholds) - 1\n",
    "        \n",
    "        self.thresholds = thresholds\n",
    "        self.labels = labels\n",
    "        self.allow_low_quality_matches = allow_low_quality_matches\n",
    "        \n",
    "    def __call__(self, match_quality_matrix: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            match_quality_matrix (Tensor[float]): an MxN tensor containing the pairwise quality between M \n",
    "                ground-truth elements and N predicted elements. All elements must be >= 0\n",
    "                (due to the use of `torch.nonzero` in `set_low_quality_matches_` methods.)\n",
    "        Returns:\n",
    "            matches (Tensor[int64]): a vector of length N, where matches[i] is a matched \n",
    "                ground-truth index in [0, M).\n",
    "            match_labels (Tensor[int8]): a vector of length N where match_labels[i] indicates\n",
    "                whether a prediction is a true or false positive or ignored.\n",
    "        \"\"\"\n",
    "        assert match_quality_matrix.dim() == 2\n",
    "        if match_quality_matrix.numel() == 0:\n",
    "            default_matches = match_quality_matrix.new_full(\n",
    "                (match_quality_matrix.size(1),), 0, dtype=torch.int64\n",
    "            )\n",
    "            \n",
    "            # No gt boxes exits. So set labels to `self.labels[0]` which is usally background.\n",
    "            # To ignore instead make labels=[-1, 0, -1, 1].\n",
    "            default_match_labels = match_quality_matrix.new_full(\n",
    "                (match_quality_matrix.size(1), ), self.labels[0], dtype=torch.int8\n",
    "            )\n",
    "            \n",
    "            return default_matches, default_match_labels\n",
    "        \n",
    "        assert torch.all(match_quality_matrix >= 0)\n",
    "        matched_vals, matches = match_quality_matrix.max(dim=0)\n",
    "        match_labels = matches.new_full(matches.size(), 1, dtype=torch.int8)\n",
    "        \n",
    "        for (l, low, high) in zip(self.labels, self.thresholds[:-1], self.thresholds[1:]):\n",
    "            low_high = (matched_vals >= low) & (matched_vals < high)\n",
    "            match_labels[low_high] = l\n",
    "            \n",
    "        if self.allow_low_quality_matches:\n",
    "            self.set_low_quality_matches_(match_labels, match_quality_matrix)\n",
    "            \n",
    "        return matches, match_labels\n",
    "    \n",
    "    def set_low_quality_matches_(self, match_labels, match_quality_matrix):\n",
    "        \"\"\"\n",
    "        Produce additional matches for predictions that have only low_quality matches.\n",
    "        \n",
    "        Specifically, for each ground-truth label element find the set of predictions that have\n",
    "        maximum overlap with it and set them to match ground-truth if unmatched previously.\n",
    "        \n",
    "        This function implements the RPN assignment case (i) in Sec. 3.1.2 of\n",
    "        :paper:`Faster R-CNN`.\n",
    "        \"\"\"\n",
    "        highest_quality_foreach_gt, _ = match_quality_matrix.max(dim=1)\n",
    "        _, pred_inds_with_highest_quality = nonzero_tuple(\n",
    "            match_quality_matrix == highest_quality_foreach_gt[:, None]\n",
    "        )\n",
    "        \n",
    "        match_labels[pred_inds_with_highest_quality] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher([0.4, 0.5], [-1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.backbone.retina_meta import RetinaNetFPN50, RetinaNetHead\n",
    "from model.backbone.resnet import ResNet50\n",
    "from model.anchor_generator import AnchorBoxGenerator\n",
    "from model.matcher import Matcher\n",
    "from utils.box_utils import pairwise_iou, cat_boxes\n",
    "from utils.shape_utils import permute_to_N_HWA_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn((16, 3, 512, 512)).to(device)\n",
    "target_boxes = [torch.randn((random.randint(1, 7), 4)).to(device) for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, torch.Size([5, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_boxes), target_boxes[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20\n",
    "num_anchors = 9\n",
    "total_anchors = (\n",
    "    64 * 64 * num_anchors\n",
    "    + 32 * 32 * num_anchors\n",
    "    + 16 * 16 * num_anchors\n",
    "    + 8 * 8 * num_anchors\n",
    "    + 4 * 4 * num_anchors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ResNet50().to(device)\n",
    "fpn_backbone = RetinaNetFPN50().to(device)\n",
    "head = RetinaNetHead(num_classes).to(device)\n",
    "anchor_gen = AnchorBoxGenerator(\n",
    "    sizes=[32., 64., 128., 256., 512.],\n",
    "    aspect_ratios=[0.5, 1., 2.],\n",
    "    scales=[1., 2 ** (1 / 3), 2 ** (2 / 3)],\n",
    "    strides=[2, 2, 2, 2, 2]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, C3, C4, C5 = backbone(data)\n",
    "P3, P4, P5, P6, P7 = fpn_backbone(C3, C4, C5)\n",
    "pred_logits, pred_bboxes = head(P3, P4, P5, P6, P7)\n",
    "all_anchors = anchor_gen([P3, P4, P5, P6, P7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36864, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_anchors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_logits = [\n",
    "      permute_to_N_HWA_K(pred_logits[k], num_classes) for k in pred_logits\n",
    "  ]\n",
    "\n",
    "reshaped_bboxes = [permute_to_N_HWA_K(pred_bboxes[k], 4) for k in pred_bboxes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_matcher = Matcher([0.4, 0.5], [-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.4, 0.5]\n",
    "labels = [-1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = -1; low = 0.4; high = 0.5\n"
     ]
    }
   ],
   "source": [
    "for (l, low, high) in zip(labels, thresholds[:-1], thresholds[1:]):\n",
    "    print(f\"l = {l}; low = {low}; high = {high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(match_qual >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_vals, matches = match_qual.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6480, -0.6852,  1.2240,  0.4158],\n",
       "        [ 0.2791, -0.7394, -1.7727, -1.5212],\n",
       "        [ 0.6535,  0.7886,  0.1682,  1.2263],\n",
       "        [ 0.3984,  1.8456, -1.0409,  2.3854]], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19.0812,  1.0406, 90.9188, 36.9594]], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[5433].view(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6535, 0.7886, 0.1682, 1.2263]], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_boxes[0][2].view(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]], device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_iou(anchors[5433].view(1, 4), target_boxes[0][3].view(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     1,     2,  ..., 49101, 49102, 49103], device='cuda:0'),)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(matches == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_labels = matches.new_full(matches.size(), 1, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = cat_boxes(all_anchors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_qual = pairwise_iou(target_boxes[0], anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert match_qual.shape == (target_boxes[0].size(0), total_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0'),\n",
       " tensor([-1, -1, -1,  ..., -1, -1, -1], device='cuda:0', dtype=torch.int8))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_matcher(match_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_idxs, anchor_labels = anchor_matcher(match_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert matched_idxs.shape == (total_anchors, )\n",
    "assert anchor_labels.shape == (total_anchors, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     1,     2,  ..., 49101, 49102, 49103], device='cuda:0'),)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(anchor_labels == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49104"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.where(matched_idxs == 3)[0].shape)[0] + (torch.where(matched_idxs == 0)[0].shape)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49104])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(anchor_labels == -1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], device='cuda:0', dtype=torch.int64),)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(anchor_labels == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], device='cuda:0', dtype=torch.int64),)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(anchor_labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49104, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_boxes[0][matched_idxs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49104"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.randn((5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.Size([10]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals, max_idxs = m.max(dim=0)\n",
    "max_vals.shape, max_idxs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
